{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig, AlbertForMaskedLM, AlbertTokenizer, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from tokenizer import SamplingAlbertTokenizer\n",
    "from dataset import BatchedLineByLineTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_tokenizer = SamplingAlbertTokenizer('tokenizer_65536.model', do_lower_case=False)\n",
    "vocab_size = len(albert_tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = BatchedLineByLineTextDataset(\n",
    "    albert_tokenizer,\n",
    "    'corpus_train.txt',\n",
    "    block_size=128\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=albert_tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_tiny_config = {\n",
    "    \"attention_probs_dropout_prob\": 0.0,\n",
    "    \"directionality\": \"bidi\",\n",
    "    \"hidden_act\": \"gelu\",\n",
    "    \"hidden_dropout_prob\": 0.0,\n",
    "    \"hidden_size\": 312,\n",
    "    \"embedding_size\": 128,\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"intermediate_size\": 1248 ,\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"num_attention_heads\": 12,\n",
    "    \"num_hidden_layers\": 4,\n",
    "    \"pooler_fc_size\": 768,\n",
    "    \"pooler_num_attention_heads\": 12,\n",
    "    \"pooler_num_fc_layers\": 3,\n",
    "    \"pooler_size_per_head\": 128,\n",
    "    \"pooler_type\": \"first_token_transform\",\n",
    "    \"type_vocab_size\": 2,\n",
    "    \"vocab_size\": vocab_size,\n",
    "    \"ln_type\":\"postln\"\n",
    "}\n",
    "\n",
    "config = AlbertConfig(**albert_tiny_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9870600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlbertForMaskedLM(config=config)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='albert_chkpt4',\n",
    "    logging_dir=f'runs/lm_{datetime.datetime.now().strftime(\"%H%M_%Y%m%d\")}',\n",
    "    logging_first_step=True,\n",
    "    logging_steps=100,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=0.000176,\n",
    "    num_train_epochs=5,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90268eccee7649acaead2f33324df80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=5.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6437f32914724ad78b25b90f81003ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=112618.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./hk_albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./hk_albert\",\n",
    "    tokenizer=albert_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] 見親連燈唱好邊隻 就邊隻跌[SEP]',\n",
       "  'score': 0.06418969482183456,\n",
       "  'token': 8,\n",
       "  'token_str': '▁'},\n",
       " {'sequence': '[CLS] 見親連燈唱好邊隻股就邊隻跌[SEP]',\n",
       "  'score': 0.05758915841579437,\n",
       "  'token': 722,\n",
       "  'token_str': '股'},\n",
       " {'sequence': '[CLS] 見親連燈唱好邊隻跌就邊隻跌[SEP]',\n",
       "  'score': 0.055454153567552567,\n",
       "  'token': 465,\n",
       "  'token_str': '跌'},\n",
       " {'sequence': '[CLS] 見親連燈唱好邊隻升就邊隻跌[SEP]',\n",
       "  'score': 0.022579167038202286,\n",
       "  'token': 283,\n",
       "  'token_str': '升'},\n",
       " {'sequence': '[CLS] 見親連燈唱好邊隻贏就邊隻跌[SEP]',\n",
       "  'score': 0.020485596731305122,\n",
       "  'token': 408,\n",
       "  'token_str': '贏'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask('見親連燈唱好邊隻[MASK]就邊隻跌')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] 水果 可以食奇異果 木瓜 菠蘿,有酵素 可以幫助消化,唔好食有糖既水果,香蕉唔好食[SEP]',\n",
       "  'score': 0.0343143455684185,\n",
       "  'token': 3287,\n",
       "  'token_str': '糖'},\n",
       " {'sequence': '[CLS] 水果 可以食奇異果 木瓜 菠蘿,有酵素 可以幫助消化,唔好食有肉既水果,香蕉唔好食[SEP]',\n",
       "  'score': 0.030959686264395714,\n",
       "  'token': 1439,\n",
       "  'token_str': '肉'},\n",
       " {'sequence': '[CLS] 水果 可以食奇異果 木瓜 菠蘿,有酵素 可以幫助消化,唔好食有飯既水果,香蕉唔好食[SEP]',\n",
       "  'score': 0.025340624153614044,\n",
       "  'token': 933,\n",
       "  'token_str': '飯'},\n",
       " {'sequence': '[CLS] 水果 可以食奇異果 木瓜 菠蘿,有酵素 可以幫助消化,唔好食有食既水果,香蕉唔好食[SEP]',\n",
       "  'score': 0.019571444019675255,\n",
       "  'token': 120,\n",
       "  'token_str': '食'},\n",
       " {'sequence': '[CLS] 水果 可以食奇異果 木瓜 菠蘿,有酵素 可以幫助消化,唔好食有好食既水果,香蕉唔好食[SEP]',\n",
       "  'score': 0.010305450297892094,\n",
       "  'token': 3291,\n",
       "  'token_str': '好食'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask('水果 可以食奇異果 木瓜 菠蘿，有酵素 可以幫助消化，唔好食有[MASK]既水果，香蕉唔好食')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] AI有自我意識後就會覺得人冇用 最後就毀滅人類[SEP]',\n",
       "  'score': 0.025629183277487755,\n",
       "  'token': 26,\n",
       "  'token_str': '人'},\n",
       " {'sequence': '[CLS] AI有自我意識後就會覺得自己冇用 最後就毀滅人類[SEP]',\n",
       "  'score': 0.021389061585068703,\n",
       "  'token': 44,\n",
       "  'token_str': '自己'},\n",
       " {'sequence': '[CLS] AI有自我意識後就會覺得能力冇用 最後就毀滅人類[SEP]',\n",
       "  'score': 0.020320802927017212,\n",
       "  'token': 841,\n",
       "  'token_str': '能力'},\n",
       " {'sequence': '[CLS] AI有自我意識後就會覺得佢冇用 最後就毀滅人類[SEP]',\n",
       "  'score': 0.018661925569176674,\n",
       "  'token': 25,\n",
       "  'token_str': '佢'},\n",
       " {'sequence': '[CLS] AI有自我意識後就會覺得你冇用 最後就毀滅人類[SEP]',\n",
       "  'score': 0.012184275314211845,\n",
       "  'token': 20,\n",
       "  'token_str': '你'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask('AI有自我意識後就會覺得[MASK]冇用 最後就毀滅人類')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] 早2日申請左,第2日就批左,第3日已經sd,話寄緊張卡比你[SEP]',\n",
       "  'score': 0.36004412174224854,\n",
       "  'token': 9,\n",
       "  'token_str': ','},\n",
       " {'sequence': '[CLS] 早2日申請左,第2日就批左,第3日已經sd 左話寄緊張卡比你[SEP]',\n",
       "  'score': 0.10268153250217438,\n",
       "  'token': 68,\n",
       "  'token_str': '左'},\n",
       " {'sequence': '[CLS] 早2日申請左,第2日就批左,第3日已經sd email話寄緊張卡比你[SEP]',\n",
       "  'score': 0.058936793357133865,\n",
       "  'token': 1680,\n",
       "  'token_str': 'email'},\n",
       " {'sequence': '[CLS] 早2日申請左,第2日就批左,第3日已經sd d話寄緊張卡比你[SEP]',\n",
       "  'score': 0.0200739074498415,\n",
       "  'token': 19,\n",
       "  'token_str': 'd'},\n",
       " {'sequence': '[CLS] 早2日申請左,第2日就批左,第3日已經sd post話寄緊張卡比你[SEP]',\n",
       "  'score': 0.01853850670158863,\n",
       "  'token': 96,\n",
       "  'token_str': 'post'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask('早2日申請左，第2日就批左，第3日已經sd [MASK]話寄緊張卡比你')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] office細唔在講,腦細中意放左工星期6日都叫你做野[SEP]',\n",
       "  'score': 0.03942243009805679,\n",
       "  'token': 163,\n",
       "  'token_str': '叫'},\n",
       " {'sequence': '[CLS] office細唔在講,腦細中意放左工星期6日都比你做野[SEP]',\n",
       "  'score': 0.031365975737571716,\n",
       "  'token': 75,\n",
       "  'token_str': '比'},\n",
       " {'sequence': '[CLS] office細唔在講,腦細中意放左工星期6日都要你做野[SEP]',\n",
       "  'score': 0.028297707438468933,\n",
       "  'token': 35,\n",
       "  'token_str': '要'},\n",
       " {'sequence': '[CLS] office細唔在講,腦細中意放左工星期6日都幫你做野[SEP]',\n",
       "  'score': 0.02787698246538639,\n",
       "  'token': 307,\n",
       "  'token_str': '幫'},\n",
       " {'sequence': '[CLS] office細唔在講,腦細中意放左工星期6日都係你做野[SEP]',\n",
       "  'score': 0.02096981182694435,\n",
       "  'token': 11,\n",
       "  'token_str': '係'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask('office細唔在講，腦細中意放左工星期6日都[MASK]你做野')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}